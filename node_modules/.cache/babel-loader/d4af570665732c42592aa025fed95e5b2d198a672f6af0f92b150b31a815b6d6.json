{"ast":null,"code":"var _jsxFileName = \"/media/mobcoder/HDD 1TB1/vashuddha/src/component/Modal.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useState } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport openmic from \"../images/openmic.svg\";\nimport micophone from '../images/microphone.gif';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction Modal(props) {\n  _s();\n  const [string, setString] = useState('');\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition,\n    interimTranscript,\n    finalTranscript\n  } = useSpeechRecognition();\n  useEffect(() => {\n    if (transcript && listening) {\n      props.handleChange(transcript);\n    } else if (finalTranscript && !listening) {\n      props.handleSubmit();\n      resetTranscript();\n      props.isClose();\n    } else if (!finalTranscript && !listening) {\n      setString('Didnt get that');\n    }\n  }, [transcript, listening]);\n  useEffect(() => {\n    if (props.open) {\n      StartListening();\n    }\n  }, [props.open]);\n  const StartListening = () => {\n    setTimeout(() => {\n      SpeechRecognition.startListening();\n      setString('Speak Now');\n      setTimeout(() => {\n        setString('Listening...');\n      }, [3000]);\n    }, 100);\n  };\n  if (!browserSupportsSpeechRecognition) {\n    return /*#__PURE__*/_jsxDEV(\"span\", {\n      children: \"Browser doesn't support speech recognition.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 46,\n      columnNumber: 12\n    }, this);\n  }\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    id: \"myModal\",\n    className: `${props.open ? \"modal-open\" : \"modal-close\"}`,\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"modal-content\",\n      children: [/*#__PURE__*/_jsxDEV(\"span\", {\n        className: \"close\",\n        onClick: () => props.isClose(),\n        children: \"\\xD7\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 54,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: [/*#__PURE__*/_jsxDEV(\"p\", {\n          children: [\"Microphone: \", listening ? \"on\" : \"off\"]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 58,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"mic-main\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            style: {\n              marginRight: '20%'\n            },\n            children: /*#__PURE__*/_jsxDEV(\"h1\", {\n              children: transcript ? transcript : string\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 61,\n              columnNumber: 17\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 60,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            children: listening ? /*#__PURE__*/_jsxDEV(\"div\", {\n              children: /*#__PURE__*/_jsxDEV(\"img\", {\n                src: micophone,\n                width: \"400\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 68,\n                columnNumber: 32\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 68,\n              columnNumber: 27\n            }, this) : !transcript && /*#__PURE__*/_jsxDEV(\"div\", {\n              children: /*#__PURE__*/_jsxDEV(\"img\", {\n                onClick: SpeechRecognition.startListening,\n                src: openmic,\n                width: \"200\",\n                className: \"cursor-poin\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 68,\n                columnNumber: 91\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 68,\n              columnNumber: 86\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 66,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 59,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 57,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 53,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 49,\n    columnNumber: 5\n  }, this);\n}\n_s(Modal, \"qNtsJTjkv4Lfuf9RdG/HNPJ+ayc=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = Modal;\nexport default Modal;\nvar _c;\n$RefreshReg$(_c, \"Modal\");","map":{"version":3,"names":["React","useEffect","useState","SpeechRecognition","useSpeechRecognition","openmic","micophone","Modal","props","string","setString","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","interimTranscript","finalTranscript","handleChange","handleSubmit","isClose","open","StartListening","setTimeout","startListening","marginRight"],"sources":["/media/mobcoder/HDD 1TB1/vashuddha/src/component/Modal.js"],"sourcesContent":["import React, { useEffect, useState } from \"react\";\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\";\nimport openmic from \"../images/openmic.svg\";\nimport micophone from '../images/microphone.gif'\nfunction Modal(props) {\n    const [string, setString] = useState('')\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition,\n    interimTranscript,\n    finalTranscript,\n  } = useSpeechRecognition();\n\n\n  useEffect(() => {\n    if (transcript&&listening) {\n      props.handleChange(transcript);\n    }else if(finalTranscript&&!listening){\n        props.handleSubmit()\n        resetTranscript()\n        props.isClose()\n    }else if(!finalTranscript&&!listening){\n        setString('Didnt get that')\n    }\n  }, [transcript,listening]);\n\n  useEffect(()=>{\nif(props.open){\n    StartListening()\n}\n  },[props.open])\n  const StartListening = ()=>{\n    setTimeout(() => {\n        SpeechRecognition.startListening()\n        setString('Speak Now')\n        setTimeout(()=>{\n        setString('Listening...')\n        },[3000])\n    }, 100);\n  }\n  if (!browserSupportsSpeechRecognition) {\n    return <span>Browser doesn't support speech recognition.</span>;\n  }\n  return (\n    <div\n      id=\"myModal\"\n      className={`${props.open ? \"modal-open\" : \"modal-close\"}`}\n    >\n      <div className=\"modal-content\">\n        <span className=\"close\" onClick={() => props.isClose()}>\n          &times;\n        </span>\n        <div>\n          <p>Microphone: {listening ? \"on\" : \"off\"}</p>\n          <div className=\"mic-main\">\n            <div style={{marginRight:'20%'}}>\n                <h1>\n\n            {transcript?transcript:string}\n                </h1>\n            </div>\n            <div>\n              {\n                listening?<div><img src={micophone} width='400'/></div>:!transcript&&<div><img onClick={SpeechRecognition.startListening} src={openmic} width='200' className=\"cursor-poin\"/></div>\n              }\n            </div>\n          </div>\n          \n          \n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default Modal;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,QAAQ,QAAQ,OAAO;AAClD,OAAOC,iBAAiB,IACtBC,oBAAoB,QACf,0BAA0B;AACjC,OAAOC,OAAO,MAAM,uBAAuB;AAC3C,OAAOC,SAAS,MAAM,0BAA0B;AAAA;AAChD,SAASC,KAAK,CAACC,KAAK,EAAE;EAAA;EAClB,MAAM,CAACC,MAAM,EAAEC,SAAS,CAAC,GAAGR,QAAQ,CAAC,EAAE,CAAC;EAC1C,MAAM;IACJS,UAAU;IACVC,SAAS;IACTC,eAAe;IACfC,gCAAgC;IAChCC,iBAAiB;IACjBC;EACF,CAAC,GAAGZ,oBAAoB,EAAE;EAG1BH,SAAS,CAAC,MAAM;IACd,IAAIU,UAAU,IAAEC,SAAS,EAAE;MACzBJ,KAAK,CAACS,YAAY,CAACN,UAAU,CAAC;IAChC,CAAC,MAAK,IAAGK,eAAe,IAAE,CAACJ,SAAS,EAAC;MACjCJ,KAAK,CAACU,YAAY,EAAE;MACpBL,eAAe,EAAE;MACjBL,KAAK,CAACW,OAAO,EAAE;IACnB,CAAC,MAAK,IAAG,CAACH,eAAe,IAAE,CAACJ,SAAS,EAAC;MAClCF,SAAS,CAAC,gBAAgB,CAAC;IAC/B;EACF,CAAC,EAAE,CAACC,UAAU,EAACC,SAAS,CAAC,CAAC;EAE1BX,SAAS,CAAC,MAAI;IAChB,IAAGO,KAAK,CAACY,IAAI,EAAC;MACVC,cAAc,EAAE;IACpB;EACE,CAAC,EAAC,CAACb,KAAK,CAACY,IAAI,CAAC,CAAC;EACf,MAAMC,cAAc,GAAG,MAAI;IACzBC,UAAU,CAAC,MAAM;MACbnB,iBAAiB,CAACoB,cAAc,EAAE;MAClCb,SAAS,CAAC,WAAW,CAAC;MACtBY,UAAU,CAAC,MAAI;QACfZ,SAAS,CAAC,cAAc,CAAC;MACzB,CAAC,EAAC,CAAC,IAAI,CAAC,CAAC;IACb,CAAC,EAAE,GAAG,CAAC;EACT,CAAC;EACD,IAAI,CAACI,gCAAgC,EAAE;IACrC,oBAAO;MAAA,UAAM;IAA2C;MAAA;MAAA;MAAA;IAAA,QAAO;EACjE;EACA,oBACE;IACE,EAAE,EAAC,SAAS;IACZ,SAAS,EAAG,GAAEN,KAAK,CAACY,IAAI,GAAG,YAAY,GAAG,aAAc,EAAE;IAAA,uBAE1D;MAAK,SAAS,EAAC,eAAe;MAAA,wBAC5B;QAAM,SAAS,EAAC,OAAO;QAAC,OAAO,EAAE,MAAMZ,KAAK,CAACW,OAAO,EAAG;QAAA,UAAC;MAExD;QAAA;QAAA;QAAA;MAAA,QAAO,eACP;QAAA,wBACE;UAAA,WAAG,cAAY,EAACP,SAAS,GAAG,IAAI,GAAG,KAAK;QAAA;UAAA;UAAA;UAAA;QAAA,QAAK,eAC7C;UAAK,SAAS,EAAC,UAAU;UAAA,wBACvB;YAAK,KAAK,EAAE;cAACY,WAAW,EAAC;YAAK,CAAE;YAAA,uBAC5B;cAAA,UAEHb,UAAU,GAACA,UAAU,GAACF;YAAM;cAAA;cAAA;cAAA;YAAA;UACpB;YAAA;YAAA;YAAA;UAAA,QACH,eACN;YAAA,UAEIG,SAAS,gBAAC;cAAA,uBAAK;gBAAK,GAAG,EAAEN,SAAU;gBAAC,KAAK,EAAC;cAAK;gBAAA;gBAAA;gBAAA;cAAA;YAAE;cAAA;cAAA;cAAA;YAAA,QAAM,GAAC,CAACK,UAAU,iBAAE;cAAA,uBAAK;gBAAK,OAAO,EAAER,iBAAiB,CAACoB,cAAe;gBAAC,GAAG,EAAElB,OAAQ;gBAAC,KAAK,EAAC,KAAK;gBAAC,SAAS,EAAC;cAAa;gBAAA;gBAAA;gBAAA;cAAA;YAAE;cAAA;cAAA;cAAA;YAAA;UAAM;YAAA;YAAA;YAAA;UAAA,QAEjL;QAAA;UAAA;UAAA;UAAA;QAAA,QACF;MAAA;QAAA;QAAA;QAAA;MAAA,QAGF;IAAA;MAAA;MAAA;MAAA;IAAA;EACF;IAAA;IAAA;IAAA;EAAA,QACF;AAEV;AAAC,GAvEQE,KAAK;EAAA,QASRH,oBAAoB;AAAA;AAAA,KATjBG,KAAK;AAyEd,eAAeA,KAAK;AAAC;AAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}